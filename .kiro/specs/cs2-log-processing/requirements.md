# Requirements Document

## Introduction

This document defines the requirements for converting the existing PHP-based CS2 (Counter-Strike 2) log processing system to a Node.js/MERN stack implementation. The system processes CS2 game server logs, extracts player statistics from JSON blocks, and stores them in MongoDB for leaderboard generation and match tracking.

## Glossary

- **CS2 Log File**: A text file generated by Counter-Strike 2 dedicated servers containing game events, player actions, and round statistics
- **Log Processor**: The Node.js service that reads, parses, and stores CS2 log data
- **Checkpoint File**: A text file storing the last processed line number to enable incremental log processing
- **JSON Block**: Structured player statistics embedded in CS2 logs between `JSON_BEGIN{` and `}JSON_END` markers
- **Match ID**: A unique identifier (MD5 hash) for each CS2 match session
- **Match Number**: A sequential integer identifying matches in chronological order
- **Round Number**: The current round number within a match (1-30 for competitive matches)
- **Account ID**: Steam account ID (32-bit) uniquely identifying a player
- **Server ID**: Numeric identifier for the CS2 dedicated server instance

## Requirements

### Requirement 1: Log File Upload Endpoint

**User Story:** As a CS2 server administrator, I want to upload log files from my dedicated server to the backend, so that match data can be processed and stored.

#### Acceptance Criteria

1. WHEN a POST request is received at the upload endpoint with a log file and server_id parameter, THE Log Processor SHALL save the file to the logs directory with filename format "latest_server{server_id}.log"
2. WHEN the log file upload is successful, THE Log Processor SHALL return HTTP 200 status with a success message
3. IF the log file upload fails, THEN THE Log Processor SHALL return HTTP 500 status with an error message
4. WHERE the logs directory does not exist, THE Log Processor SHALL create the directory before saving the file

### Requirement 2: Checkpoint Management

**User Story:** As a system, I want to track the last processed line number for each server, so that I can avoid reprocessing old log data and handle server restarts.

#### Acceptance Criteria

1. WHEN processing begins for a server, THE Log Processor SHALL read the checkpoint file "checkpoint_server{server_id}.txt" to determine the last processed line number
2. IF the checkpoint file does not exist, THEN THE Log Processor SHALL initialize the checkpoint value to 0
3. WHEN the checkpoint value exceeds the total lines in the log file, THE Log Processor SHALL reset the checkpoint to 0 and log a server restart detection message
4. WHEN log processing completes successfully, THE Log Processor SHALL update the checkpoint file with the total number of processed lines

### Requirement 3: JSON Block Parsing

**User Story:** As a system, I want to extract player statistics from JSON blocks in CS2 logs, so that I can store accurate match data.

#### Acceptance Criteria

1. WHEN a line containing "JSON_BEGIN{" is encountered, THE Log Processor SHALL enter JSON parsing mode
2. WHILE in JSON parsing mode, THE Log Processor SHALL extract round_number, map name, and player statistics
3. WHEN a line containing "}JSON_END" is encountered, THE Log Processor SHALL exit JSON parsing mode
4. WHEN round_number is 0, THE Log Processor SHALL skip the round as warmup data
5. THE Log Processor SHALL extract the following fields from each player entry: accountid, team, kills, deaths, assists, dmg, kdr, mvp

### Requirement 4: Bot and Invalid Player Filtering

**User Story:** As a system, I want to exclude bot players and invalid entries from the database, so that leaderboards only show real player statistics.

#### Acceptance Criteria

1. WHEN a player entry has accountid equal to 0, THE Log Processor SHALL skip the entry without logging
2. WHEN a player entry has empty or missing accountid, THE Log Processor SHALL skip the entry without logging
3. THE Log Processor SHALL only process player entries with valid non-zero accountid values

### Requirement 5: Match Detection and Tracking

**User Story:** As a system, I want to detect new matches and assign unique identifiers, so that rounds are correctly grouped by match session.

#### Acceptance Criteria

1. WHEN round_number equals 1 and the previous round_number was greater than 1, THE Log Processor SHALL detect a new match start
2. WHEN a new match is detected, THE Log Processor SHALL generate a unique match_id using MD5 hash of map name, date, timestamp, and random number
3. WHEN a new match is detected, THE Log Processor SHALL increment the match_number by 1 from the highest existing match_number in the database
4. THE Log Processor SHALL query the database for the maximum match_number on startup to continue the sequence
5. THE Log Processor SHALL assign the current match_id and match_number to all rounds until a new match is detected

### Requirement 6: Duplicate Prevention

**User Story:** As a system, I want to prevent duplicate entries in the database, so that player statistics remain accurate and consistent.

#### Acceptance Criteria

1. WHEN processing a player round entry, THE Log Processor SHALL check if the combination of accountid, match_id, and round_number already exists in the database
2. IF the entry already exists in the database, THEN THE Log Processor SHALL skip insertion and log a duplicate detection message
3. THE Log Processor SHALL maintain an in-memory cache of processed entries during the current processing session to avoid redundant database queries
4. WHEN the same round_number is encountered multiple times in the log, THE Log Processor SHALL process only the first occurrence

### Requirement 7: Database Storage

**User Story:** As a system, I want to store processed player statistics in MongoDB, so that the data can be queried for leaderboards and match history.

#### Acceptance Criteria

1. WHEN a valid player entry is processed, THE Log Processor SHALL insert a document into the MongoDB collection with fields: accountid, team, kills, deaths, assists, dmg, kdr, mvp, map, round_number, match_id, match_number, match_date, match_datetime, server_id
2. THE Log Processor SHALL use the existing Match model or create a new CS2Match model for storing match data
3. THE Log Processor SHALL handle database connection errors gracefully and log error messages
4. WHEN insertion fails due to duplicate key constraint, THE Log Processor SHALL log the duplicate and continue processing

### Requirement 8: Processing Summary and Logging

**User Story:** As a system administrator, I want to see detailed processing logs and summaries, so that I can monitor the log processing system and troubleshoot issues.

#### Acceptance Criteria

1. WHEN processing begins, THE Log Processor SHALL log the total lines, last processed line, and lines to be processed
2. WHEN a new match is detected, THE Log Processor SHALL log the match number and match_id
3. WHEN a player entry is processed, THE Log Processor SHALL log the accountid, match number, round number, and kill/death stats
4. WHEN processing completes, THE Log Processor SHALL log a summary including: inserted count, skipped count, map name, and total processed lines
5. THE Log Processor SHALL log server restart detection when checkpoint exceeds log file length

### Requirement 9: Map Name Detection

**User Story:** As a system, I want to detect the map name from log files, so that match data includes the correct map information.

#### Acceptance Criteria

1. WHEN a line containing 'Loading map "' is encountered, THE Log Processor SHALL extract the map name using regex pattern
2. THE Log Processor SHALL use the detected map name for all subsequent match entries until a new map is loaded
3. IF no map name is detected, THEN THE Log Processor SHALL use "unknown" as the default map name

### Requirement 10: Incremental Processing

**User Story:** As a system, I want to process only new log lines since the last checkpoint, so that processing is efficient and avoids redundant work.

#### Acceptance Criteria

1. WHEN the checkpoint value is less than the total log lines, THE Log Processor SHALL process only lines from checkpoint+1 to the end
2. WHEN the checkpoint value equals the total log lines, THE Log Processor SHALL exit with a "no new data" message
3. THE Log Processor SHALL use array slicing to skip already processed lines before parsing
